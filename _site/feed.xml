<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.10.0">Jekyll</generator><link href="http://0.0.0.0:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://0.0.0.0:4000/" rel="alternate" type="text/html" /><updated>2025-05-08T00:16:06-05:00</updated><id>http://0.0.0.0:4000/feed.xml</id><title type="html">EMNLP 2025</title><subtitle>Official website for the 2025 Conference on Empirical Methods in Natural Language Processing</subtitle><author><name>Haiyue Song</name></author><entry><title type="html">Criteria for Determining Irresponsible Reviewers</title><link href="http://0.0.0.0:4000/reviewer-policies/" rel="alternate" type="text/html" title="Criteria for Determining Irresponsible Reviewers" /><published>2025-05-06T00:00:00-05:00</published><updated>2025-05-06T00:00:00-05:00</updated><id>http://0.0.0.0:4000/reviewer-policies</id><content type="html" xml:base="http://0.0.0.0:4000/reviewer-policies/"><![CDATA[<p>This post accompanies the ARR post <a href="https://aclrollingreview.org/incentives2025">Changes to reviewer volunteering requirement and incentives</a>, and defines the specific criteria for what we will deem as “Highly Irresponsible” reviewers. While the focus here is <em>reviewers</em>, we will use similar criteria for determining irresponsible <em>Area chairs (ACs)</em>.</p>

<h3 id="1-non-submitted-reviews">1. Non-submitted reviews</h3>

<p>If a reviewer fails to submit their reviews by the official deadline and has not submitted a <a href="https://aclrollingreview.org/reviewerguidelines#q-what-should-i-do-if-i-cannot-complete-my-assignment-due-to-a-personal-emergency">personal emergency declaration</a> (<strong>note</strong>: declaring a personal emergency after the review deadline will not be considered) will automatically be flagged as “Highly Irresponsible”.</p>

<h3 id="2-extremely-terse-or-unprofessional-reviews">2. Extremely terse or unprofessional reviews</h3>

<p>Where the submissions are good-faith work that merits a serious review (otherwise a short review can suffice, assuming it clearly explains the fundamental problems with that work), reviews that only contain a single argument (1-2 sentences) and no constructive feedback should be flagged. We may also penalize reviews that are extremely unprofessional in tone (e.g., rude, racist, sexist, ableist, etc. content; I4 in the list of <a href="https://aclrollingreview.org/authors#step2.2">12 commonly reported issues</a>), even if they are otherwise detailed.</p>

<p>Here are some guidelines for determining whether to consider a submission to be in good faith: At minimum, a good faith article states the contribution up front and provides an evaluation that supports that. If the writing is so poor that the intended contribution can’t be identified or the article is missing an evaluation positioned as supporting that, then the article does not warrant a serious review. If the issue is just that the stated contribution is not clear, or the evaluation is not sufficient or rigorous enough, that does warrant a serious review. Furthermore, if the paper shows a naivete about the state of the art, the paper still warrants a serious review, but if the paper shows a complete lack of awareness of work in the field (for example, if virtually all of the citations are from another field), then the paper is not a good faith submission. Even interdisciplinary papers should show an awareness of the audience they are submitting their work to.</p>

<h3 id="3-llm-generated-reviews">3. LLM-generated reviews</h3>

<p>As per the <a href="https://www.aclweb.org/adminwiki/index.php/ACL_Policy_on_Publication_Ethics#Guidelines_for_Generative_Assistance_in_Peer_Review">ACL Policy on Publication Ethics</a>, it is acceptable to use LLMs for paraphrasing, grammatical checks and proof-reading, but not for the content of the (meta-)reviews. Furthermore, the content of both the submission and (meta-)review is confidential. Therefore, even for acceptable purposes such as proofreading, it <strong>must not</strong> be passed on to non-privacy-preserving third parties, such as commercial LLM services, which may store it.</p>

<p>Authors will be able to flag such cases and present any evidence they have to support their allegation. While there is no definitive way of determining whether a review was (entirely) generated by an LLM, the Program Chairs will review the evidence and only proceed in cases where there is no reasonable doubt.</p>

<h2 id="flagging-review-process">Flagging review process</h2>

<p>The process is specified in the <a href="https://aclrollingreview.org/incentives2025">ARR post</a>. Ultimately, all decisions will be made by the Program Chairs after a careful review of all evidence. Reviewers/ACs will be able to appeal to the publication ethics committee<sup id="fnref:1"><a href="#fn:1" class="footnote" rel="footnote" role="doc-noteref">1</a></sup> if they want to dispute the Program Chairs decisions.</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1">
      <p><a href="https://www.aclweb.org/adminwiki/index.php/Process_for_ACL_Publication_Ethics_Review">https://www.aclweb.org/adminwiki/index.php/Process_for_ACL_Publication_Ethics_Review</a> <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name>Haiyue Song</name></author><summary type="html"><![CDATA[This post accompanies the ARR post Changes to reviewer volunteering requirement and incentives, and defines the specific criteria for what we will deem as “Highly Irresponsible” reviewers. While the focus here is reviewers, we will use similar criteria for determining irresponsible Area chairs (ACs).]]></summary></entry><entry><title type="html">New Tracks at EMNLP 2025 and Their Relationship to ARR Tracks</title><link href="http://0.0.0.0:4000/track-changes/" rel="alternate" type="text/html" title="New Tracks at EMNLP 2025 and Their Relationship to ARR Tracks" /><published>2025-05-06T00:00:00-05:00</published><updated>2025-05-06T00:00:00-05:00</updated><id>http://0.0.0.0:4000/track-changes</id><content type="html" xml:base="http://0.0.0.0:4000/track-changes/"><![CDATA[<p>As we prepare for EMNLP 2025, many of you may have noticed that we are introducing several new tracks and making adjustments to our area list. You might also notice that there are some differences between the EMNLP tracks and those currently reflected in the ACL Rolling Review (ARR) system. Note that the EMNLP tracks will apply only at the commitment stage, i.e. after the ARR reviewing cycle is finished. At initial submission time you will need to choose among the ARR tracks. To help with this transition, the ARR area keywords have been updated to better align with the new EMNLP tracks. You can search for your preferred sub-areas and their associated ARR track here: <a href="https://aclrollingreview.org/areas">https://aclrollingreview.org/areas</a>. We wanted to take a moment to explain the motivations behind these decisions and how they fit into the broader picture of our field’s evolution.</p>

<h2 id="why-we-are-adding-new-tracks">Why We Are Adding New Tracks</h2>

<p>The field of NLP is rapidly evolving. Areas that were once niche have grown into major subfields, and entirely new topics have emerged. To encourage cutting-edge research, EMNLP 2025 will:</p>

<ul>
  <li>
    <p><strong>Create space and foster community for fast-growing and emerging research areas</strong> that deserve focused attention.</p>
  </li>
  <li>
    <p><strong>Experiment with track structure</strong> in a way that informs <strong>future ARR reforms</strong>.<br />
EMNLP, as a one-off event, gives us the flexibility to pilot changes that can later help ARR evolve thoughtfully and responsibly.</p>
  </li>
</ul>

<p>While <strong>ARR needs to maintain long-term stability</strong>, commitment stages of individual conferences can be <strong>more agile</strong> – and the lessons from this conference will provide valuable feedback and inform more permanent changes to the ARR tracks going forward.</p>

<h2 id="whats-being-added-and-the-relationship-with-arr-existing-tracks">What’s Being Added and The Relationship with ARR Existing Tracks</h2>

<p>Here’s a summary of the new or adjusted tracks, organized by the reasoning behind them:</p>

<h3 id="1-recognizing-emerging-research-areas">1. Recognizing Emerging Research Areas</h3>

<p>We are creating or highlighting tracks to reflect research areas that have recently expanded rapidly:</p>

<ul>
  <li><strong>Safety and Alignment in LLMs</strong></li>
  <li><strong>AI/LLM Agents</strong></li>
  <li><strong>Code Models</strong></li>
  <li><strong>Neurosymbolic Approaches to NLP</strong></li>
  <li><strong>Mathematical, Symbolic, and Logical Reasoning</strong></li>
  <li><strong>Generalizability and Transfer</strong></li>
  <li><strong>LLM Efficiency</strong></li>
</ul>

<h3 id="2-expandingclarifying-existing-areas">2. Expanding/Clarifying Existing Areas</h3>

<p>To clarify reviewer expertise and topic boundaries, we also propose the following changes:</p>

<ul>
  <li>
    <p><strong>Information Extraction and Retrieval</strong><br />
Merged from the tracks of <em>information extraction and Information Retrieval and Text Mining</em> tracks</p>
  </li>
  <li>
    <p><strong>Interpretability, Model Editing, and Explainability</strong>:<br />
Expanded from the <em>Interpretability and Analysis</em> track</p>
  </li>
  <li>
    <p><strong>Hierarchical Structure Prediction, Syntax, and Parsing</strong>:<br />
Added hierarchical structure prediction as a keyword under the <em>Syntax and Parsing</em> track to better reflect current research directions.</p>
  </li>
</ul>

<h3 id="3-mapping-to-arr-tracks">3. Mapping to ARR Tracks</h3>

<p>The following EMNLP 2025 tracks will be organized as sub-areas under the ARR track <strong>Language Modeling:</strong></p>

<ul>
  <li><strong>Safety and Alignment in LLMs</strong></li>
  <li><strong>AI/LLM Agents</strong></li>
  <li><strong>Code Models</strong></li>
  <li><strong>Neurosymbolic Approaches to NLP</strong></li>
</ul>

<p>The following EMNLP 2025 tracks will be organized as sub-areas under the ARR track <strong>Machine Learning for NLP:</strong></p>

<ul>
  <li><strong>Mathematical, Symbolic, and Logical Reasoning</strong></li>
  <li><strong>Generalizability and Transfer</strong></li>
</ul>

<p>The EMNLP 2025 track of <strong>LLM Efficiency</strong> will be organized as sub-areas under the ARR track <strong>Efficient/Low-Resource Methods for NLP.</strong></p>

<p>The EMNLP 2025 track of <strong>Information Extraction and Retrieval</strong> essentially merged the ARR tracks of <strong>Information Extraction</strong> and <strong>Information Retrieval and Text Mining.</strong></p>

<h2 id="closing-remarks">Closing Remarks</h2>

<p>The track updates at EMNLP 2025 are more than just adjustments for this year — they are an opportunity to <strong>proactively shape the future of our community</strong>.</p>

<p>By experimenting with new tracks and structures now, we hope to <strong>gain valuable insights</strong> into submission patterns, reviewing quality, and community needs — insights that can <strong>inform the evolution of the ACL Rolling Review</strong> for the better.</p>

<p>We look forward to your submissions and to working together to build the next generation of conferences!</p>]]></content><author><name>Haiyue Song</name></author><summary type="html"><![CDATA[As we prepare for EMNLP 2025, many of you may have noticed that we are introducing several new tracks and making adjustments to our area list. You might also notice that there are some differences between the EMNLP tracks and those currently reflected in the ACL Rolling Review (ARR) system. Note that the EMNLP tracks will apply only at the commitment stage, i.e. after the ARR reviewing cycle is finished. At initial submission time you will need to choose among the ARR tracks. To help with this transition, the ARR area keywords have been updated to better align with the new EMNLP tracks. You can search for your preferred sub-areas and their associated ARR track here: https://aclrollingreview.org/areas. We wanted to take a moment to explain the motivations behind these decisions and how they fit into the broader picture of our field’s evolution.]]></summary></entry></feed>